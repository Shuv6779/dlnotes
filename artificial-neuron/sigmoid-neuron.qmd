# The sigmoid neuron
The sigmoid neuron is a real-valued function mapping from $\mathbb{R}^n$ to $\mathbb{R}$. It is capable of fitting real-valued functions unlike the perceptron which could only fit boolean functions. It does this by replacing the thresholding logic of the perceptron with a logistic function.

## Motivation
The sigmoid neuron addresses some limitations of the perceptron:
1. The perceptron could only fit binary functions
2. The perceptron is not a fully differentiable model.
3. Consider two inputs to a single-input perceptron: $\theta+d\theta$ and $\theta-d\theta$. Due to the nature of the thresholding logic, the perceptron will output $1$ on the first and $0$ on the second if regardless of how small $d\theta$ is.

## Mathematical formulation
The sigmoid neuron is a real-valued function $f_{k, \theta, \textbf{w}}:\mathbb{R}^n\to\mathbb{R}$ where $k$ and $\theta$ are positive real numbers and $\textbf{w}$ is a real valued vector such that 
$$
f_{k, \theta, \textbf{w}}(\textbf{x}) =  g_k(\theta + \textbf{w}\cdot\textbf{x})
g_k(\textbf{y}) = \frac{1}{1+e^{-ky}}
$$

$g_k(\textbf{y})$ is a logistic function with a maximum value of $1$ and steepness of $k$. However, $g_k$ is not just restricted to the logistic function, in fact it can take on any function belonging to the sigmoid family of functions. Another virtue of the sigmoid neuron is the fact that it is **differentiable for all input values**.

### Interpretation as probability
Since the sigmoid neuron has a range of $(0, 1)$ it can be interpreted as a probability/liklehood/certainty of a particular event. This interpretation has many applications.

