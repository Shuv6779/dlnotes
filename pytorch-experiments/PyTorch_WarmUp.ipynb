{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b16c4e3-92a3-4cab-ae10-e2aa9006f6ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "240bbe4c-36e3-4d9b-b678-bf3af785b874",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scalar\n",
    "scalar=torch.tensor(5)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "757bdd2b-89e1-43f6-a395-e9c2f4b679b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c65cc2bd-d3ce-4c21-a555-35185c3a48b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cab585e-f2f4-4d9b-be1e-55cf6cf6a945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To convert the tensor into a python integer (Only works with scalars(one element tesors))\n",
    "scalar.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad390fb0-1059-495f-adc4-d30e0994d39e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([64, 53])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectors are one dimensional tensors but can contain multiple numbers\n",
    "#Vector\n",
    "vector=torch.tensor([64,53])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "401778d4-9d87-422f-a62c-e3b70d280bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf133331-9ff1-4168-a300-56ba23e38da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shape of a vector tells us how to elemenst inside a vecotr are arranged\n",
    "vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf1c12d-dd33-47c9-952f-bf5879d62df0",
   "metadata": {},
   "source": [
    "It gives two because you put two numbers into the vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06d61281-0147-453e-bf68-752bdc30bc7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   73, 75732],\n",
       "        [   47,   228]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrices are vectors with TWO dimensions.\n",
    "MATRIX=torch.tensor([[73,75732],[47,228]])\n",
    "MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36653eb5-afc4-43d7-8f6a-7d786585323b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78227e6e-f925-4c7a-8c01-9c25aa7931ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0ea4d86-a22b-43ca-a52d-c1c4b36d48e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 3, 5, 2, 5])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex0=torch.tensor([1,3,5,2,5])\n",
    "ex0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cff943c8-2e90-46ea-882b-c96b0b8f62d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex0.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12caf02a-96a3-4906-8ae2-1dcb344c9be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14115fee-d511-4e29-8e40-2db45ac39c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 4],\n",
       "        [3, 5],\n",
       "        [7, 1]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex=torch.tensor([[2,4],\n",
    "                 [3,5],\n",
    "                 [7,1]])\n",
    "ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9ef67bd-b391-435c-a7d5-a01d01390e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71f87fa7-41dd-41b8-a55a-2a6cb0b5a117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f066c6c1-c888-4e7d-a4c4-2de39108b84f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  2,   8],\n",
       "        [  4,   1],\n",
       "        [ 75,  49],\n",
       "        [719,  38]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex2=torch.tensor([[2,8],[4,1],[75,49],[719,38]])\n",
    "ex2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "836dc93c-8a16-4105-b2fb-c7e75d6b320a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex2.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43cb831a-c5d8-4c76-a7b2-86332b2e09ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3839517-1909-4c13-aed2-5acbdf49bc24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  3,   5,   1,   5,   2],\n",
       "        [  4,   1,  48,   6,   6],\n",
       "        [ 29, 653,   5,  32,   6]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex3=torch.tensor([[3,5,1,5,2],[4,1,48,6,6],[29,653,5,32,6]])\n",
    "ex3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd2053f7-885d-42e1-b5e9-91f1c8b44140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex3.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db3f615f-168e-476f-b1b1-c8bd769cee4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc266613-aa80-4f85-8fe6-ab99df566b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6929, 0.7619, 0.8812, 0.1728, 0.7774],\n",
       "         [0.1881, 0.8344, 0.2487, 0.1713, 0.0635],\n",
       "         [0.8207, 0.0427, 0.4943, 0.6729, 0.1494],\n",
       "         [0.9979, 0.5296, 0.1641, 0.2162, 0.8707]],\n",
       "\n",
       "        [[0.9711, 0.8039, 0.5501, 0.8385, 0.4529],\n",
       "         [0.8605, 0.9396, 0.1137, 0.6444, 0.1301],\n",
       "         [0.5181, 0.2647, 0.0880, 0.2270, 0.6046],\n",
       "         [0.1972, 0.4333, 0.7171, 0.9073, 0.4942]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex4=torch.rand(2,4,5)\n",
    "ex4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5942ed41-348a-452d-9b7c-ee8a3e783d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex4.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "599b7c97-5f7f-4b5b-a7b8-23975ec5d1c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 5])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb92fcff-1b8c-4543-a838-d17fac73d463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7789, 0.1682],\n",
       "         [0.0094, 0.2445],\n",
       "         [0.8911, 0.8321]],\n",
       "\n",
       "        [[0.1200, 0.3260],\n",
       "         [0.3457, 0.2957],\n",
       "         [0.4098, 0.7482]],\n",
       "\n",
       "        [[0.3866, 0.8168],\n",
       "         [0.4305, 0.2413],\n",
       "         [0.8641, 0.3003]],\n",
       "\n",
       "        [[0.0059, 0.5729],\n",
       "         [0.3734, 0.2545],\n",
       "         [0.6897, 0.0118]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex5=torch.rand(4,3,2)\n",
    "ex5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d80f8a4-95a4-454e-a163-c388f2c44584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex5.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e7cbfcf7-f01f-4c1e-811e-722fcd59375f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea3c4b91-2163-4a48-96c1-2a47c8b87f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.9931, 0.1168, 0.6716, 0.1681, 0.4354],\n",
       "          [0.5095, 0.5501, 0.7275, 0.0465, 0.7774],\n",
       "          [0.4128, 0.4399, 0.2902, 0.0855, 0.0089]],\n",
       "\n",
       "         [[0.1425, 0.3474, 0.4017, 0.3200, 0.7337],\n",
       "          [0.9222, 0.8889, 0.0237, 0.6372, 0.7848],\n",
       "          [0.7411, 0.3156, 0.3671, 0.3514, 0.2942]],\n",
       "\n",
       "         [[0.4480, 0.2421, 0.8844, 0.7294, 0.2559],\n",
       "          [0.3428, 0.3152, 0.7915, 0.2410, 0.8635],\n",
       "          [0.3690, 0.6569, 0.6382, 0.9779, 0.8057]],\n",
       "\n",
       "         [[0.1643, 0.5866, 0.4884, 0.3975, 0.0647],\n",
       "          [0.2299, 0.9929, 0.2179, 0.5184, 0.9253],\n",
       "          [0.0221, 0.1830, 0.4195, 0.6929, 0.5759]]],\n",
       "\n",
       "\n",
       "        [[[0.9516, 0.1911, 0.7478, 0.5186, 0.0919],\n",
       "          [0.9706, 0.1871, 0.0041, 0.0241, 0.3407],\n",
       "          [0.3150, 0.0383, 0.3816, 0.4461, 0.0336]],\n",
       "\n",
       "         [[0.3946, 0.5747, 0.8072, 0.5822, 0.2242],\n",
       "          [0.5933, 0.1112, 0.2253, 0.3920, 0.7162],\n",
       "          [0.0453, 0.3017, 0.8724, 0.9880, 0.8047]],\n",
       "\n",
       "         [[0.2868, 0.9855, 0.8950, 0.5879, 0.9848],\n",
       "          [0.7208, 0.2909, 0.0047, 0.7693, 0.8669],\n",
       "          [0.5762, 0.1647, 0.9850, 0.8583, 0.7998]],\n",
       "\n",
       "         [[0.5251, 0.0835, 0.2995, 0.9137, 0.0712],\n",
       "          [0.5983, 0.1219, 0.1641, 0.6429, 0.7465],\n",
       "          [0.3766, 0.3345, 0.8705, 0.9843, 0.4925]]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex6=torch.rand(2,4,3,5)\n",
    "ex6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "28b3afad-49b8-4a6f-bffa-0da2f5255ff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex6.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b0a0df10-38a5-4f81-95b5-80932b32126a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 3, 5])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex6.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518566f3-fb1c-48fb-96f2-9662390abbfd",
   "metadata": {},
   "source": [
    "## Probably, ndim gives the number of dimensions and shape gives us the dimensions of the tensor(or matrix) in the form of $n$x$m$x$...$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a19704ec-4373-4062-979c-c7466a779a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  473,   478,    37],\n",
       "         [  273,   472,    72],\n",
       "         [72819,    47,   281]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR=torch.tensor([[[473,478,37],\n",
    "                      [273,472,72],\n",
    "                      [72819,47,281]]])\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "638675a9-227f-4a9c-8c01-68aa88295d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cb9a33b2-abe0-424b-bdc5-e652bcde72e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a45731c0-8cfc-4c8e-9320-8809f7273a06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  2,   3,  73],\n",
       "         [ 27,  73,  21],\n",
       "         [ 27,  65,  36],\n",
       "         [ 10, 738,  98],\n",
       "         [472,  73,  63],\n",
       "         [ 73, 482,  63]],\n",
       "\n",
       "        [[  2,   3,  73],\n",
       "         [ 27,  73,  21],\n",
       "         [ 27,  65,  36],\n",
       "         [ 10, 738,  98],\n",
       "         [472,  73,  63],\n",
       "         [ 73, 482,  63]]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR2=torch.tensor([[[2,3,73],[27,73,21],\n",
    "                      [27,65,36],[10,738,98],\n",
    "                      [472,73,63],[73,482,63]],[[2,3,73],[27,73,21],\n",
    "                      [27,65,36],[10,738,98],\n",
    "                      [472,73,63],[73,482,63]]])\n",
    "TENSOR2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c2cf1943-7f0b-42de-abdc-24d8c3f8ffea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR2.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "56bf3e8e-dab5-483f-a546-b5315e444017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6, 3])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b256f1a-661e-459c-820b-d6300448f7b9",
   "metadata": {},
   "source": [
    "By Convention, we use all caps for tensors and matrices and lower case for vectors and scalars. There are no terms as scalars, vectors, matrices in the syntax. All of them are tensors. The shape and dimensions of the tensor define the term used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9673c52-da49-4f96-91cf-e593e0cc8e15",
   "metadata": {},
   "source": [
    "To Summarize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd530df-71ac-4326-8975-2cad65a5555e",
   "metadata": {},
   "source": [
    "| Name | What is it? | Number of dimensions | Lower or upper (usually/example) |\n",
    "| ----- | ----- | ----- | ----- |\n",
    "| **scalar** | a single number | 0 | Lower (`a`) | \n",
    "| **vector** | a number with direction (e.g. wind speed with direction) but can also have many other numbers | 1 | Lower (`y`) |\n",
    "| **matrix** | a 2-dimensional array of numbers | 2 | Upper (`Q`) |\n",
    "| **tensor** | an n-dimensional array of numbers | can be any number, a 0-dimension tensor is a scalar, a 1-dimension tensor is a vector | Upper (`X`) | \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "715cf306-06c7-4e92-a6e3-e63f28451690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.9307, 0.2047, 0.9102],\n",
       "         [0.7537, 0.7382, 0.4093],\n",
       "         [0.8215, 0.6938, 0.3436],\n",
       "         [0.6726, 0.6349, 0.0772],\n",
       "         [0.1314, 0.2939, 0.3545]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random tensors\n",
    "rand_ten= torch.rand(size=(5,3))\n",
    "rand_ten,rand_ten.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5709c416-dc3b-4778-8313-e9b34d1bcde4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_ten.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0900c3-1e47-482d-a3c2-e857e134369e",
   "metadata": {},
   "source": [
    "For Example, if we want to create a tensor for the common image shape  of (224, 224, 3) ie, (Height, Width, Color Channels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ce5301d9-cd5b-404a-a0c4-45a82e8ed1a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7235, 0.3475, 0.1128,  ..., 0.7870, 0.7319, 0.6244],\n",
       "         [0.9130, 0.7502, 0.0262,  ..., 0.5601, 0.3764, 0.1332],\n",
       "         [0.0326, 0.0666, 0.0381,  ..., 0.5440, 0.0450, 0.7834],\n",
       "         ...,\n",
       "         [0.3312, 0.3437, 0.1137,  ..., 0.1090, 0.7219, 0.3526],\n",
       "         [0.7155, 0.0402, 0.0209,  ..., 0.2060, 0.9748, 0.8547],\n",
       "         [0.4337, 0.9035, 0.8697,  ..., 0.0928, 0.6882, 0.6823]],\n",
       "\n",
       "        [[0.3749, 0.1274, 0.0679,  ..., 0.9208, 0.5695, 0.1757],\n",
       "         [0.6695, 0.3983, 0.9633,  ..., 0.1439, 0.8342, 0.6253],\n",
       "         [0.7849, 0.3406, 0.0078,  ..., 0.8696, 0.3369, 0.3489],\n",
       "         ...,\n",
       "         [0.9902, 0.3673, 0.7743,  ..., 0.1442, 0.0641, 0.2402],\n",
       "         [0.9773, 0.6198, 0.4050,  ..., 0.0056, 0.1235, 0.4614],\n",
       "         [0.1538, 0.6105, 0.3765,  ..., 0.9220, 0.4059, 0.7821]],\n",
       "\n",
       "        [[0.9005, 0.4082, 0.3391,  ..., 0.3896, 0.9649, 0.3884],\n",
       "         [0.1506, 0.6456, 0.9188,  ..., 0.2503, 0.1541, 0.5787],\n",
       "         [0.9122, 0.1805, 0.5534,  ..., 0.4106, 0.3451, 0.9317],\n",
       "         ...,\n",
       "         [0.5601, 0.9080, 0.5195,  ..., 0.4821, 0.3404, 0.2160],\n",
       "         [0.1838, 0.3120, 0.9754,  ..., 0.7687, 0.1310, 0.8943],\n",
       "         [0.3991, 0.7130, 0.2392,  ..., 0.6545, 0.3912, 0.6865]]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_image=torch.rand(size=(3,224,224))\n",
    "rand_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "084831bf-1f1e-4081-a922-970fb6f5d131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_image.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "92cb4508-7b11-45e1-b657-08e9dd6b5ab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be1e72d-54ab-483d-9516-20f6ee0bead5",
   "metadata": {},
   "source": [
    "To create a tensor with just aeros (used to mask values which we dont need the model to learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5bb1184c-2b98-4ef7-b642-1d61a9f81f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros=torch.zeros(size=(5,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "61c9dabd-ce30-4069-a1b4-be59b3209b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "58d16e68-d220-48bd-823b-97f151d7b6fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "982a61ae-29e1-4cd9-ae23-bd808e3f0bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ones=torch.ones(size=(5,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2e3e83a5-c587-4eeb-b5c6-d95ebc2b9bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "00bbe5a7-6867-4986-8da6-4e7e537b7186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eedb56d0-a994-4ca2-91c0-563efc7896f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_ten=torch.arange(start=0,end=10,step=1)\n",
    "zero_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5c338cd8-61c5-4121-98c6-a8733eacfa33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 3, 6, 9])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_ten_three=torch.arange(start=0,end=10,step=3)\n",
    "zero_ten_three"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edb5b6c-7dae-4785-8783-f686617dfd92",
   "metadata": {},
   "source": [
    "To create a tensor with same shape as another :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "32bd123d-c340-4bc9-8bf4-d3b3ee25e85b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ten_ones=torch.ones_like(input=zero_ten_three)\n",
    "ten_ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "83ebff67-ed40-4e84-9ff6-e68554929067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 1.])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_float_32=torch.tensor([3.0,6.0,1.0],\n",
    "                            dtype=None)\n",
    "tensor_float_32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fa17de63-d8f9-488b-9835-34849553359d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_float_32.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c0cef4eb-efe2-44cc-b523-ef5413a68326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_float_32.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "816d5cdb-9382-479b-8790-7ab192839025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_float_32.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7332dbdd-fccf-409d-ae5a-db3c53816912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_float_32.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "03897547-7290-4072-97c4-415600c68464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.0000,  6.0000, 10.2031], dtype=torch.float16)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_float_16=torch.tensor([3.0,6.0,10.2],\n",
    "                            dtype=torch.float16)\n",
    "tensor_float_16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d779e61b-eba5-4466-9975-adcf855349d4",
   "metadata": {},
   "source": [
    "# Why are there discrepensies with the precision digit after the decimal point?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd780b55-f237-4aaa-84d7-756232ae6d00",
   "metadata": {},
   "source": [
    "It is because of float16 is less precise than float32 so due to the roundoff error there r slight dicrepancies but since it takes less space, its used in places where memory is a scarce resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "57eabf28-4f6d-40b8-b291-9cf388e8e19b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_float_16.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cbb8f5be-9a72-47cc-aeb3-d7b8a42ed179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0316, 0.7063, 0.1055, 0.7054],\n",
       "        [0.5167, 0.1111, 0.8219, 0.5887],\n",
       "        [0.8636, 0.1042, 0.0918, 0.9745],\n",
       "        [0.4481, 0.7971, 0.5347, 0.9317],\n",
       "        [0.7867, 0.1356, 0.0354, 0.8421]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_tensor=torch.rand(5,4)\n",
    "some_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "23ffa995-8189-4166-9110-73d0b8436670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "29645d1e-27d6-4313-b56a-99f14959a23e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f2f36068-c5df-4a8b-847c-ddb792e85480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 4])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "96c7f6e4-7881-4c42-8dc8-92b5bd340cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor : torch.Size([5, 4])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of tensor : {some_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "158f4eea-6eee-4570-b16a-55e490fb8330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Type of tensor : torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(f\"Data Type of tensor : {some_tensor.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "535a6dfc-7a06-4935-ac89-9fdba525dc22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device of tensor : cpu\n"
     ]
    }
   ],
   "source": [
    "print(f\"Device of tensor : {some_tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52919ee-7982-4290-a8d8-2d7c00b3bc9c",
   "metadata": {},
   "source": [
    "### Tensor Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b797a79e-71bb-4069-94f6-289ed3b6e7f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([14, 12, 18])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens=torch.tensor([4,2,8])\n",
    "tens+10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9687f082-dc80-4786-8010-c8bdb66e7098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 2, 8])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0e1a2915-4359-4a66-843b-d29adda30063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([40, 20, 80])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c7aea42e-ca7e-439d-a5ab-25ca2789a30c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 2, 8])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2d7344be-d620-4d93-9dd7-af3b4e2bc36c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-6, -8, -2])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5676fe12-651b-43cf-a439-b93b14b8960a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-6, -8, -2])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens=tens-10\n",
    "tens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "43882641-e451-4f87-b144-f01ddd9a195b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-60, -80, -20])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mul(tens,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "319e5225-b1f6-4b0e-9a47-e6e2e9881833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-6, -8, -2])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bd6b3924-d095-4fac-930a-1c903db174d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 2, 8])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(tens,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b3e666f7-fd9d-40dc-98f3-c36c8b419765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-16, -18, -12])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sub(tens,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6b18e030-971e-49c2-ae4a-f5cec57c4df5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.6000, -0.8000, -0.2000])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.div(tens,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b3ccd891-8526-4528-8b1e-57c37f08490e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-6, -8, -2])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "729d346c-11d8-403d-8f35-e497238b9367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.6000, -0.8000, -0.2000])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9257df17-9aab-43c6-b7f2-207bcb47a68d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-6, -8, -2])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ba7fe638-9da2-439a-8ade-1796e35a63ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "tens=tens/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "75b23fef-2666-4d92-a0e9-77d234d1a85d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.6000, -0.8000, -0.2000])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "603b1850-00d7-48e3-a10d-cdd2439b24fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3d3fe188-545c-4d2e-a971-1ec3cdeacf09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 5, 9])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens=torch.tensor([3,5,9])\n",
    "tens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3f3426-cf4c-413e-adfc-737b54c78a70",
   "metadata": {},
   "source": [
    "Element wise multiplicaton:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2b103177-4529-42ae-b984-8adcaf2846d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9, 25, 81])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens * tens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4103f76a-3569-4303-a3bd-82a87c1ecc81",
   "metadata": {},
   "source": [
    "### Matrix Mult"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070d7a80-1cab-4dbe-9d2c-ed2f234e6b4b",
   "metadata": {},
   "source": [
    "For Matrix Mult, there are two rules to it :\n",
    "* Inner dimensions should match\n",
    "    ex : (3,2) @ (2,5) Works but \n",
    "         (2,5) @ (3,7) Doesn't\n",
    "* The resulting matrix should take the outer dimensions\n",
    "\n",
    "Note: \"@\" in Python is the symbol for matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f9ddf0b2-5004-40e9-a245-5dd404b4f462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens=torch.tensor([1,4,8])\n",
    "tens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0f1fc9ad-6e30-4b46-a984-fba4c3a3b367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1, 16, 64])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens*tens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f760a905-3621-4330-b3f2-6870dfcbfe10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(81)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens.matmul(tens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "40acc516-1119-4423-9518-8ee54d28c1c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(81)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(tens,tens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9cac6ada-a6bb-4bfe-a888-09bcca7ff298",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(81)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens@tens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d79ac0-a0c7-466f-8496-a1766a402f7b",
   "metadata": {
    "tags": []
   },
   "source": [
    "We can do matrix mult more primitively by setting up 'for' loops but it is very computationally expensive and shdnt be done unless we hv a better algorithm than matmul."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6ea900a9-0d36-4ee9-8075-a8cace6861be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 353 µs, sys: 0 ns, total: 353 µs\n",
      "Wall time: 240 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(81)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "matmul=0\n",
    "for i in range(len(tens)):\n",
    "    matmul+=tens[i]*tens[i]\n",
    "matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d85cee2f-d7cc-4d0f-bb94-de56872a3972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 107 µs, sys: 19 µs, total: 126 µs\n",
      "Wall time: 89.9 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(81)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "tens.matmul(tens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1917cb9d-1f5a-4dbe-9ee9-bb40402d564a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 115 µs, sys: 21 µs, total: 136 µs\n",
      "Wall time: 97.5 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(81)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "torch.matmul(tens,tens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bcd7aa0d-2737-4066-ae83-3c7d1a443de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tens_a=torch.tensor([[2,6],\n",
    "                    [3,6],\n",
    "                    [1,7]])\n",
    "tens_b=torch.tensor([[48,82],\n",
    "                    [72,83],\n",
    "                    [24,57]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c1538a64-ee21-40b1-9c26-8d41528de186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2]), torch.Size([3, 2]))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens_a.shape, tens_b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "dff5370f-aebe-4f68-8d13-7997df042976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 96, 492],\n",
       "        [216, 498],\n",
       "        [ 24, 399]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens_a*tens_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ab0394e4-4d09-403b-9a0c-84b05dc30922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matmul(tens_a,tens_b)\n",
    "# This wont run coz the shapes r 3*2 and 3*2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101878c2-8dcc-4c56-89d8-86baa18164ff",
   "metadata": {},
   "source": [
    "We can make it work by transposing either of the matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d796d54c-c9ea-4e97-ad17-ad08a16f3503",
   "metadata": {},
   "source": [
    "* torch.transpose(input, dim0, dim1) - where input is the desired tensor to transpose and dim0 and dim1 are the dimensions to be swapped.\n",
    "* tensor.T - where tensor is the desired tensor to transpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8002c741-056b-4fde-8e8c-3721f65c6dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 6],\n",
       "        [3, 6],\n",
       "        [1, 7]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens_a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "cf7a73d4-0817-466f-962f-049a9fc0232e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[48, 82],\n",
       "        [72, 83],\n",
       "        [24, 57]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "60a007de-afca-4214-ae29-d7e83a0d9cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[48, 72, 24],\n",
       "        [82, 83, 57]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens_b.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e714df49-bfc7-4ca1-b814-1febdad1443e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[588, 642, 390],\n",
       "        [636, 714, 414],\n",
       "        [622, 653, 423]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(tens_a,tens_b.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4c848524-6e5e-49ad-9d35-92004c67c17a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[588, 642, 390],\n",
       "        [636, 714, 414],\n",
       "        [622, 653, 423]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens_a.matmul(tens_b.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f96a9462-b99e-4c36-9130-b6f7732025a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[588, 642, 390],\n",
       "        [636, 714, 414],\n",
       "        [622, 653, 423]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens_a.mm(tens_b.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4fe5669c-e6d7-4632-9d3c-9e91d1033fdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[588, 642, 390],\n",
       "        [636, 714, 414],\n",
       "        [622, 653, 423]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(tens_a,tens_b.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fe95b4-df0f-4020-ab03-dfc6ea5c5aaf",
   "metadata": {},
   "source": [
    "The torch.nn.Linear() module also known as a feed-forward layer or fully connected layer, implements a matrix multiplication between an input x and a weights matrix A.\n",
    "\n",
    "$$y = x \\cdot A^\\intercal + b$$\n",
    "\n",
    "x is the input to the layer (deep learning is a stack of layers like torch.nn.Linear() and others on top of each other).\n",
    "\n",
    "A is the weights matrix created by the layer, this starts out as random numbers that get adjusted as a neural network learns to better represent patterns in the data (notice the T, that's because the weights matrix gets transposed).\n",
    "Note: You might also often see W or another letter like X used to showcase the weights matrix.\n",
    "\n",
    "b is the bias term used to slightly offset the weights and inputs.\n",
    "\n",
    "y is the output (a manipulation of the input in the hopes to discover patterns in it).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "df8eef5a-c399-4ed2-a6f2-525cf36aa694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([3, 2])\n",
      "\n",
      "Output:\n",
      "tensor([[ 1.0348,  0.4592,  0.3892,  0.0690,  0.3858,  0.3514],\n",
      "        [ 0.9272,  0.3378,  0.3622, -0.0094,  0.4842,  0.3286],\n",
      "        [ 1.1711,  0.5868,  0.4136,  0.1433,  0.2987,  0.3971]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "\n",
      "Output shape: torch.Size([3, 6])\n"
     ]
    }
   ],
   "source": [
    "# Since the linear layer starts with a random weights matrix, let's make it reproducible (more on this later)\n",
    "torch.manual_seed(42)\n",
    "# This uses matrix multiplication\n",
    "linear = torch.nn.Linear(in_features=2, # in_features = matches inner dimension of input \n",
    "                         out_features=6) # out_features = describes outer value \n",
    "x = torch.rand(3,2)\n",
    "output = linear(x)\n",
    "print(f\"Input shape: {x.shape}\\n\")\n",
    "print(f\"Output:\\n{output}\\n\\nOutput shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29080843-e62f-41b4-9457-279c43fcf7b5",
   "metadata": {},
   "source": [
    "### Agregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b945409d-3cd5-453f-9d5c-7f6ced672ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.arange(0,100,10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fa9126de-762c-431b-8fc3-9007da22f2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum: 0\n",
      "Maximum: 90\n",
      "Mean: 45.0\n",
      "Sum: 450\n"
     ]
    }
   ],
   "source": [
    "print(f\"Minimum: {x.min()}\")\n",
    "print(f\"Maximum: {x.max()}\")\n",
    "print(f\"Mean: {x.type(torch.float32).mean()}\")\n",
    "print(f\"Sum: {x.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6771df75-1513-4305-90f0-137cec5514d5",
   "metadata": {},
   "source": [
    "`print(f\"Mean: {x.mean()}\")`  will error  \n",
    "Mean won't work without the float datatype :  \n",
    "`print(f\"Mean: {x.type(torch.float32).mean()}\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8fed37c2-4e7e-4a29-bbb6-d8bbf7f59ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "44eeb9c0-3992-477d-9e2e-9b84235b2b6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(90), tensor(0))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.max(),x.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9e87063c-ed82-44d9-ad11-567198e3ecc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(45.)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.type(torch.float32).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc36a1fa-fd1b-4fa3-b41f-91f770fcffaf",
   "metadata": {},
   "source": [
    "We can also use `torch.max()` , `torch.min()` etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "bda76d2a-6b18-4a06-8655-8bf4417049ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(90), tensor(0))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(x), torch.min(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db50fac5-c253-4ed9-9e51-fdee1298744c",
   "metadata": {},
   "source": [
    "We can use `argmax(.)`,`argmin(.)` to find the index of the max or min value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d0569315-8822-45ba-921f-f49ade21603f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(9), tensor(0))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(x), torch.argmin(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d73492-1620-4017-a118-0871f8bd9bd7",
   "metadata": {},
   "source": [
    "### Changing Datatype of a tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906809e9-800b-4654-a65e-6890063b4142",
   "metadata": {},
   "source": [
    "To change the data type of a tensor we use `type(type.__)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5e50f0dd-5828-49d6-9f8e-2b9cf08262fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91]), torch.int64)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens=torch.arange(1,100,10)\n",
    "tens,tens.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "116f4a4b-4b33-468e-8535-c90f690f2eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1., 11., 21., 31., 41., 51., 61., 71., 81., 91.]), torch.float32)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens_float32=tens.type(torch.float32)\n",
    "tens_float32,tens_float32.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f06038a3-5a5a-48c8-9160-13415a3ed028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91]), torch.int64)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens_int64=tens_float32.type(torch.int64)\n",
    "tens_int64,tens_int64.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1727faba-7db4-40cb-9dc4-d3aba2aeb93a",
   "metadata": {},
   "source": [
    "### Reshaping, Stacking, Squeezing, Unsqueezing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca87ff1e-3f14-41a8-92d8-3cb928c88212",
   "metadata": {},
   "source": [
    "#### Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b5e82023-fcf7-4383-b0e7-76e6c2daf7e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3, 4, 5, 6, 7]), torch.Size([7]))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.arange(1,8)\n",
    "x,x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a40702e2-deb1-4408-8d10-01295f596a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4, 5, 6, 7]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.reshape(1,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "864cf7e9-206c-4c7c-9bb1-4618655946b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [4],\n",
       "        [5],\n",
       "        [6],\n",
       "        [7]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.reshape(7,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "df3b51b3-b783-426e-ad58-ca40b345feca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3, 4, 5, 6, 7]]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.reshape(1,1,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8e4e2be7-2711-4bea-a7fc-8b43fc8d9ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1]],\n",
       "\n",
       "        [[2]],\n",
       "\n",
       "        [[3]],\n",
       "\n",
       "        [[4]],\n",
       "\n",
       "        [[5]],\n",
       "\n",
       "        [[6]],\n",
       "\n",
       "        [[7]]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.reshape(7,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "24488289-87d2-4255-a4b2-a21f2e9b3ccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[24, 13, 16, 19],\n",
       "          [12, 19, 22,  5],\n",
       "          [ 0,  4,  8, 14]],\n",
       " \n",
       "         [[14,  1,  7, 10],\n",
       "          [11, 22,  2, 19],\n",
       "          [ 7, 23, 18, 19]]]),\n",
       " torch.Size([2, 3, 4]))"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens=torch.randint(low=0, high=25, size=(2,3,4))\n",
    "tens,tens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "bff40601-c594-4ee5-b950-a1adcfb87fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[24, 13, 16, 19]],\n",
       "\n",
       "         [[12, 19, 22,  5]],\n",
       "\n",
       "         [[ 0,  4,  8, 14]]],\n",
       "\n",
       "\n",
       "        [[[14,  1,  7, 10]],\n",
       "\n",
       "         [[11, 22,  2, 19]],\n",
       "\n",
       "         [[ 7, 23, 18, 19]]]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens.reshape(2,3,1,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "388d3ffe-f516-4362-831a-fbfbc984a090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[24, 13, 16, 19, 12, 19, 22,  5,  0,  4,  8, 14],\n",
       "        [14,  1,  7, 10, 11, 22,  2, 19,  7, 23, 18, 19]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens.reshape(2,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "57edf69d-d2f0-497b-a3ba-7611c40749cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[24, 13, 16],\n",
       "         [19, 12, 19]],\n",
       "\n",
       "        [[22,  5,  0],\n",
       "         [ 4,  8, 14]],\n",
       "\n",
       "        [[14,  1,  7],\n",
       "         [10, 11, 22]],\n",
       "\n",
       "        [[ 2, 19,  7],\n",
       "         [23, 18, 19]]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens.reshape(4,2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "626b6c08-6b7c-41e0-9046-11bc41afce35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[24, 13],\n",
       "         [16, 19],\n",
       "         [12, 19]],\n",
       "\n",
       "        [[22,  5],\n",
       "         [ 0,  4],\n",
       "         [ 8, 14]],\n",
       "\n",
       "        [[14,  1],\n",
       "         [ 7, 10],\n",
       "         [11, 22]],\n",
       "\n",
       "        [[ 2, 19],\n",
       "         [ 7, 23],\n",
       "         [18, 19]]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens.reshape(4,3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "570c5725-5343-4b22-8677-c2e717263c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[24, 13, 16, 19],\n",
       "        [12, 19, 22,  5],\n",
       "        [ 0,  4,  8, 14],\n",
       "        [14,  1,  7, 10],\n",
       "        [11, 22,  2, 19],\n",
       "        [ 7, 23, 18, 19]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens.reshape(6,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "24c65169-5b66-405d-8c5d-ab7a652a4907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[24, 13, 16],\n",
       "        [19, 12, 19],\n",
       "        [22,  5,  0],\n",
       "        [ 4,  8, 14],\n",
       "        [14,  1,  7],\n",
       "        [10, 11, 22],\n",
       "        [ 2, 19,  7],\n",
       "        [23, 18, 19]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens.reshape(8,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a51f733-de78-4298-9e62-4d4356eb5c59",
   "metadata": {},
   "source": [
    "#### View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f4d215d6-6e6d-47d3-96e6-8a331c642d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "z=tens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b9c020dd-57a2-41c3-ab7e-7b5abb96255e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[24, 13, 16, 19, 12, 19, 22,  5,  0,  4,  8, 14],\n",
       "        [14,  1,  7, 10, 11, 22,  2, 19,  7, 23, 18, 19]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=z.view(2,12)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5707e8f2-f780-410d-9da2-90190bf08560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[24, 13, 16, 19, 12, 19, 22,  5,  0,  4,  8, 14],\n",
       "        [14,  1,  7, 10, 11, 22,  2, 19,  7, 23, 18, 19]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=z.reshape(2,12)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "cc50aa3c-0f03-40ac-8cb6-6e6a593f39f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 5,  5,  5,  5],\n",
       "         [12, 19, 22,  5],\n",
       "         [ 0,  4,  8, 14]],\n",
       "\n",
       "        [[ 5,  5,  5,  5],\n",
       "         [11, 22,  2, 19],\n",
       "         [ 7, 23, 18, 19]]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[:,0]=5\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "351c2dc2-67d7-4b4c-8e03-a9219230c003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5,  5,  5,  5, 12, 19, 22,  5,  0,  4,  8, 14],\n",
       "        [ 5,  5,  5,  5, 11, 22,  2, 19,  7, 23, 18, 19]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ff6710fd-3ded-403c-90aa-794e837b1887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5,  5,  5,  5, 12, 19, 22,  5,  0,  4,  8, 14],\n",
       "        [ 5,  5,  5,  5, 11, 22,  2, 19,  7, 23, 18, 19]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df761578-52bc-41ad-af93-81ba2b2fe059",
   "metadata": {},
   "source": [
    "Even when we change the viewed and reshaped tensors both the viewed and reshaped tensor change the original tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "516f2c04-9352-4a60-9ec6-5325b3262674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6969,    5,    5,    5,   12,   19,   22,    5,    0,    4,    8,   14],\n",
       "        [   5,    5,    5,    5,   11,   22,    2,   19,    7,   23,   18,   19]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,0]=6969\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "cf8b2b4b-c6ba-4391-8644-26937131ce59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[6969,    5,    5,    5],\n",
       "         [  12,   19,   22,    5],\n",
       "         [   0,    4,    8,   14]],\n",
       "\n",
       "        [[   5,    5,    5,    5],\n",
       "         [  11,   22,    2,   19],\n",
       "         [   7,   23,   18,   19]]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "6d0792b5-d309-4e86-9971-850bca0d388e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6969,    5,    5,    5,   12,   19,   22,    5,    0,    4,    8,   14],\n",
       "        [   5,    5,    5,    5,   11,   22,    2,   19,    7,   23,   18,   19]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3b4a218d-e265-4425-8845-78d4133f11d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10,  5,  5,  5, 12, 19, 22,  5,  0,  4,  8, 14],\n",
       "        [ 5,  5,  5,  5, 11, 22,  2, 19,  7, 23, 18, 19]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0,0]=10\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "e420c05e-0078-4d9b-84d6-2cb379dd1900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[10,  5,  5,  5],\n",
       "         [12, 19, 22,  5],\n",
       "         [ 0,  4,  8, 14]],\n",
       "\n",
       "        [[ 5,  5,  5,  5],\n",
       "         [11, 22,  2, 19],\n",
       "         [ 7, 23, 18, 19]]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e82548-9764-4cba-bec0-f32bd0b5ded2",
   "metadata": {},
   "source": [
    "This is because both view and reshape share the underlying data with teh original tensor so making changes in any will reflect on the other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d2ce9b-3037-4c6e-9d1d-b688e1b7d779",
   "metadata": {},
   "source": [
    "#### Squeeze / Unsqueeze"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2b2329-3b7c-4b3f-b60d-5e5274911656",
   "metadata": {},
   "source": [
    "`squeeze()` returns a tensor with all the dimensions of size 1 removed. Unsqueeze adds a dimension of size 1 inserted at the specified position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0d698576-4c30-4c01-9379-7ec7b1ee448b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[10,  5,  5,  5],\n",
       "          [12, 19, 22,  5],\n",
       "          [ 0,  4,  8, 14]],\n",
       " \n",
       "         [[ 5,  5,  5,  5],\n",
       "          [11, 22,  2, 19],\n",
       "          [ 7, 23, 18, 19]]]),\n",
       " torch.Size([2, 3, 4]))"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens,tens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3bf3c651-190f-4d69-b656-4bc2e7ec81fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[10,  5,  5,  5],\n",
       "         [12, 19, 22,  5],\n",
       "         [ 0,  4,  8, 14]],\n",
       "\n",
       "        [[ 5,  5,  5,  5],\n",
       "         [11, 22,  2, 19],\n",
       "         [ 7, 23, 18, 19]]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699575a4-6ae5-4a8f-9022-3d7bb4620d03",
   "metadata": {},
   "source": [
    "When theres no size 1 dimension, squeeze returns the original tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "bdacea64-0090-4525-9cf5-68473f1f133e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 1,  2,  3,  4,  5]],\n",
       " \n",
       "         [[ 6,  7,  8,  9, 10]],\n",
       " \n",
       "         [[11, 12, 13, 14, 15]],\n",
       " \n",
       "         [[16, 17, 18, 19, 20]],\n",
       " \n",
       "         [[21, 22, 23, 24, 25]]]),\n",
       " torch.Size([5, 1, 5]))"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex1=torch.arange(1,26).reshape(5,1,5)\n",
    "ex1,ex1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "5e33afa0-9633-4b50-829e-278cf0540b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1,  2,  3,  4,  5],\n",
       "         [ 6,  7,  8,  9, 10],\n",
       "         [11, 12, 13, 14, 15],\n",
       "         [16, 17, 18, 19, 20],\n",
       "         [21, 22, 23, 24, 25]]),\n",
       " torch.Size([5, 5]))"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex1.squeeze(), ex1.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7cf1c395-22ba-4f84-be01-7ff19f4d0e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 1,  2,  3,  4,  5]],\n",
       " \n",
       "         [[ 6,  7,  8,  9, 10]],\n",
       " \n",
       "         [[11, 12, 13, 14, 15]],\n",
       " \n",
       "         [[16, 17, 18, 19, 20]],\n",
       " \n",
       "         [[21, 22, 23, 24, 25]]]),\n",
       " torch.Size([5, 1, 5]))"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex1, ex1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e524bdb8-9e93-4b04-a26b-26c5924a485d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 1,  2,  3,  4,  5]],\n",
       " \n",
       "          [[ 6,  7,  8,  9, 10]],\n",
       " \n",
       "          [[11, 12, 13, 14, 15]],\n",
       " \n",
       "          [[16, 17, 18, 19, 20]],\n",
       " \n",
       "          [[21, 22, 23, 24, 25]]]]),\n",
       " torch.Size([1, 5, 1, 5]))"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex1.unsqueeze(0), ex1.unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b3a7c691-d5c2-41c0-97db-533e93757ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 1,  2,  3,  4,  5]]],\n",
       " \n",
       " \n",
       "         [[[ 6,  7,  8,  9, 10]]],\n",
       " \n",
       " \n",
       "         [[[11, 12, 13, 14, 15]]],\n",
       " \n",
       " \n",
       "         [[[16, 17, 18, 19, 20]]],\n",
       " \n",
       " \n",
       "         [[[21, 22, 23, 24, 25]]]]),\n",
       " torch.Size([5, 1, 1, 5]))"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex1.unsqueeze(1), ex1.unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "6542ae78-871c-4b43-ba01-b4586a2ab4f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 1,  2,  3,  4,  5],\n",
       "          [ 6,  7,  8,  9, 10],\n",
       "          [11, 12, 13, 14, 15],\n",
       "          [16, 17, 18, 19, 20],\n",
       "          [21, 22, 23, 24, 25]]]),\n",
       " torch.Size([1, 5, 5]))"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex1.squeeze().unsqueeze(0), ex1.squeeze().unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "abe21da1-0371-4712-b707-dc275037ef8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 1,  2,  3,  4,  5]],\n",
       " \n",
       "         [[ 6,  7,  8,  9, 10]],\n",
       " \n",
       "         [[11, 12, 13, 14, 15]],\n",
       " \n",
       "         [[16, 17, 18, 19, 20]],\n",
       " \n",
       "         [[21, 22, 23, 24, 25]]]),\n",
       " torch.Size([5, 1, 5]))"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex1.squeeze().unsqueeze(1),ex1.squeeze().unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "b5acdb57-b9e6-4c84-a3d0-a191b963c772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 1,  2,  3,  4,  5]],\n",
       " \n",
       "         [[ 6,  7,  8,  9, 10]],\n",
       " \n",
       "         [[11, 12, 13, 14, 15]],\n",
       " \n",
       "         [[16, 17, 18, 19, 20]],\n",
       " \n",
       "         [[21, 22, 23, 24, 25]]]),\n",
       " torch.Size([5, 1, 5]))"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex1, ex1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "07f0a377-2699-49c1-91df-d1bfca7f3d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 1,  2,  3,  4,  5]]],\n",
       " \n",
       " \n",
       "         [[[ 6,  7,  8,  9, 10]]],\n",
       " \n",
       " \n",
       "         [[[11, 12, 13, 14, 15]]],\n",
       " \n",
       " \n",
       "         [[[16, 17, 18, 19, 20]]],\n",
       " \n",
       " \n",
       "         [[[21, 22, 23, 24, 25]]]]),\n",
       " torch.Size([5, 1, 1, 5]))"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex1.unsqueeze(2),ex1.unsqueeze(2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d5a04c70-26f0-4165-9531-6c9b3e49998e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 1],\n",
       "           [ 2],\n",
       "           [ 3],\n",
       "           [ 4],\n",
       "           [ 5]]],\n",
       " \n",
       " \n",
       "         [[[ 6],\n",
       "           [ 7],\n",
       "           [ 8],\n",
       "           [ 9],\n",
       "           [10]]],\n",
       " \n",
       " \n",
       "         [[[11],\n",
       "           [12],\n",
       "           [13],\n",
       "           [14],\n",
       "           [15]]],\n",
       " \n",
       " \n",
       "         [[[16],\n",
       "           [17],\n",
       "           [18],\n",
       "           [19],\n",
       "           [20]]],\n",
       " \n",
       " \n",
       "         [[[21],\n",
       "           [22],\n",
       "           [23],\n",
       "           [24],\n",
       "           [25]]]]),\n",
       " torch.Size([5, 1, 5, 1]))"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex1.unsqueeze(3),ex1.unsqueeze(3).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb9934f-5a67-4e2c-86e2-99e6b6d42df3",
   "metadata": {},
   "source": [
    "`ex1.unsqueeze(4),ex1.unsqueeze(4).shape` gives error dimension out of range."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758c206f-00cc-47d6-b6d1-70852a7f876f",
   "metadata": {},
   "source": [
    "#### Permute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc28ee2e-908b-470f-8ee4-e0b4a3a96441",
   "metadata": {},
   "source": [
    "`permute()` gives us a **view** by rearranging the dimensions of the input tensor according to the indices provided as arguments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "895f9bf1-7d80-4c5e-b3a9-ca080df8fcba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2,  3,  4],\n",
       "         [ 5,  6,  7,  8],\n",
       "         [ 9, 10, 11, 12]],\n",
       "\n",
       "        [[13, 14, 15, 16],\n",
       "         [17, 18, 19, 20],\n",
       "         [21, 22, 23, 24]]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens=torch.arange(1,25).reshape(2,3,4)\n",
    "tens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "3bc4091e-0c3c-43b6-91e9-eaf493dfe97f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 1,  5,  9],\n",
       "          [13, 17, 21]],\n",
       " \n",
       "         [[ 2,  6, 10],\n",
       "          [14, 18, 22]],\n",
       " \n",
       "         [[ 3,  7, 11],\n",
       "          [15, 19, 23]],\n",
       " \n",
       "         [[ 4,  8, 12],\n",
       "          [16, 20, 24]]]),\n",
       " torch.Size([4, 2, 3]))"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens.permute(2,0,1), tens.permute(2,0,1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd58e50-c9ba-4e67-8793-c7ed3667b2fb",
   "metadata": {},
   "source": [
    "### Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e65b4be5-dfef-4911-ba46-21b2a345dc67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 1,  2,  3,  4],\n",
       "          [ 5,  6,  7,  8],\n",
       "          [ 9, 10, 11, 12],\n",
       "          [13, 14, 15, 16]],\n",
       " \n",
       "         [[17, 18, 19, 20],\n",
       "          [21, 22, 23, 24],\n",
       "          [25, 26, 27, 28],\n",
       "          [29, 30, 31, 32]]]),\n",
       " torch.Size([2, 4, 4]))"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens=torch.arange(1,33).reshape(2,4,4)\n",
    "tens,tens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "03744cb8-39f1-4d28-bc59-e15db8998858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.2815]]]), torch.Size([1, 1, 1]), 3)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking out some doubts about 1D tensors\n",
    "tens=torch.randn(1)\n",
    "tens,tens.shape,tens.ndim\n",
    "\n",
    "x=tens.unsqueeze(1)\n",
    "tens.unsqueeze(1),tens.unsqueeze(1).shape,tens.unsqueeze(1).ndim\n",
    "\n",
    "x.unsqueeze(1)\n",
    "x.unsqueeze(1),x.unsqueeze(1).shape, x.unsqueeze(1).ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "55fe92d9-fe9d-4d6b-9d08-c92bcd971159",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.2815]), tensor(0.2815))"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens, tens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "ec0188ce-3ee9-4a1f-a405-e3a0a9cd1217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[  1,   2,   3,   4,   5,   6],\n",
       "           [  7,   8,   9,  10,  11,  12],\n",
       "           [ 13,  14,  15,  16,  17,  18],\n",
       "           [ 19,  20,  21,  22,  23,  24],\n",
       "           [ 25,  26,  27,  28,  29,  30]],\n",
       " \n",
       "          [[ 31,  32,  33,  34,  35,  36],\n",
       "           [ 37,  38,  39,  40,  41,  42],\n",
       "           [ 43,  44,  45,  46,  47,  48],\n",
       "           [ 49,  50,  51,  52,  53,  54],\n",
       "           [ 55,  56,  57,  58,  59,  60]]],\n",
       " \n",
       " \n",
       "         [[[ 61,  62,  63,  64,  65,  66],\n",
       "           [ 67,  68,  69,  70,  71,  72],\n",
       "           [ 73,  74,  75,  76,  77,  78],\n",
       "           [ 79,  80,  81,  82,  83,  84],\n",
       "           [ 85,  86,  87,  88,  89,  90]],\n",
       " \n",
       "          [[ 91,  92,  93,  94,  95,  96],\n",
       "           [ 97,  98,  99, 100, 101, 102],\n",
       "           [103, 104, 105, 106, 107, 108],\n",
       "           [109, 110, 111, 112, 113, 114],\n",
       "           [115, 116, 117, 118, 119, 120]]],\n",
       " \n",
       " \n",
       "         [[[121, 122, 123, 124, 125, 126],\n",
       "           [127, 128, 129, 130, 131, 132],\n",
       "           [133, 134, 135, 136, 137, 138],\n",
       "           [139, 140, 141, 142, 143, 144],\n",
       "           [145, 146, 147, 148, 149, 150]],\n",
       " \n",
       "          [[151, 152, 153, 154, 155, 156],\n",
       "           [157, 158, 159, 160, 161, 162],\n",
       "           [163, 164, 165, 166, 167, 168],\n",
       "           [169, 170, 171, 172, 173, 174],\n",
       "           [175, 176, 177, 178, 179, 180]]]]),\n",
       " torch.Size([3, 2, 5, 6]))"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens=torch.arange(1,181).reshape(3,2,5,6)\n",
    "tens,tens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "9dffaae7-bc23-481e-96c4-64f6c6f9fb64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2,  3,  4,  5,  6],\n",
       "         [ 7,  8,  9, 10, 11, 12],\n",
       "         [13, 14, 15, 16, 17, 18],\n",
       "         [19, 20, 21, 22, 23, 24],\n",
       "         [25, 26, 27, 28, 29, 30]],\n",
       "\n",
       "        [[31, 32, 33, 34, 35, 36],\n",
       "         [37, 38, 39, 40, 41, 42],\n",
       "         [43, 44, 45, 46, 47, 48],\n",
       "         [49, 50, 51, 52, 53, 54],\n",
       "         [55, 56, 57, 58, 59, 60]]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25527b27-f078-4d4b-909c-e14d3f1cd872",
   "metadata": {},
   "source": [
    "`[0]` gives us the first $n-1$ order tensor where $n$ is the ndim of the input tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "6fd2445f-2718-42e4-8ca4-1535613b4410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3,  4,  5,  6],\n",
       "        [ 7,  8,  9, 10, 11, 12],\n",
       "        [13, 14, 15, 16, 17, 18],\n",
       "        [19, 20, 21, 22, 23, 24],\n",
       "        [25, 26, 27, 28, 29, 30]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03aa56c0-669a-471e-9f32-a91458731532",
   "metadata": {},
   "source": [
    "`[0]` gives us the first $n-2$ order tensor where $n$ is the ndim of the input tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "8b4f9b3d-7427-4dbc-b0ff-e0cd41e537ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens[0][0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00eb2bad-bef7-4e3a-b8f2-c8a172db0ba1",
   "metadata": {},
   "source": [
    "`[0]` gives us the first $n-3$ order tensor where $n$ is the ndim of the input tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "6dc12e5a-fc18-4555-a437-ffa0d9c45dbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens[0][0][0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6679dd8-4385-4820-9f06-af28c2793e18",
   "metadata": {},
   "source": [
    "`[0]` gives us the first $n-4$ order tensor where $n$ is the ndim of the input tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdaae1e0-2f24-4167-bea2-147bec97defe",
   "metadata": {},
   "source": [
    "* So in general, `[0]`$^m$ gives us the first $n-m$ tensor where n is the ndim of the input tensor and m is the number of times theres `[0]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ebbaed44-b7c2-4e39-ac3b-ed6615d9c0af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[151, 152, 153, 154, 155, 156],\n",
       "        [157, 158, 159, 160, 161, 162],\n",
       "        [163, 164, 165, 166, 167, 168],\n",
       "        [169, 170, 171, 172, 173, 174],\n",
       "        [175, 176, 177, 178, 179, 180]])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens[2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "3950738d-51dd-47a1-9188-e05295c6ae7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[151, 152, 153, 154, 155, 156],\n",
       "         [157, 158, 159, 160, 161, 162],\n",
       "         [163, 164, 165, 166, 167, 168],\n",
       "         [169, 170, 171, 172, 173, 174],\n",
       "         [175, 176, 177, 178, 179, 180]]])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens[2:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "0c501160-a21a-4abb-bd21-ef5ee0f49fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[  1,   2,   3,   4,   5,   6],\n",
       "           [  7,   8,   9,  10,  11,  12],\n",
       "           [ 13,  14,  15,  16,  17,  18],\n",
       "           [ 19,  20,  21,  22,  23,  24],\n",
       "           [ 25,  26,  27,  28,  29,  30]],\n",
       " \n",
       "          [[ 31,  32,  33,  34,  35,  36],\n",
       "           [ 37,  38,  39,  40,  41,  42],\n",
       "           [ 43,  44,  45,  46,  47,  48],\n",
       "           [ 49,  50,  51,  52,  53,  54],\n",
       "           [ 55,  56,  57,  58,  59,  60]]],\n",
       " \n",
       " \n",
       "         [[[ 61,  62,  63,  64,  65,  66],\n",
       "           [ 67,  68,  69,  70,  71,  72],\n",
       "           [ 73,  74,  75,  76,  77,  78],\n",
       "           [ 79,  80,  81,  82,  83,  84],\n",
       "           [ 85,  86,  87,  88,  89,  90]],\n",
       " \n",
       "          [[ 91,  92,  93,  94,  95,  96],\n",
       "           [ 97,  98,  99, 100, 101, 102],\n",
       "           [103, 104, 105, 106, 107, 108],\n",
       "           [109, 110, 111, 112, 113, 114],\n",
       "           [115, 116, 117, 118, 119, 120]]],\n",
       " \n",
       " \n",
       "         [[[121, 122, 123, 124, 125, 126],\n",
       "           [127, 128, 129, 130, 131, 132],\n",
       "           [133, 134, 135, 136, 137, 138],\n",
       "           [139, 140, 141, 142, 143, 144],\n",
       "           [145, 146, 147, 148, 149, 150]],\n",
       " \n",
       "          [[151, 152, 153, 154, 155, 156],\n",
       "           [157, 158, 159, 160, 161, 162],\n",
       "           [163, 164, 165, 166, 167, 168],\n",
       "           [169, 170, 171, 172, 173, 174],\n",
       "           [175, 176, 177, 178, 179, 180]]]]),\n",
       " torch.Size([3, 2, 5, 6]))"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens, tens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "299d6331-4f10-4d34-a091-b330c6527d2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 25,  26,  27,  28,  29,  30],\n",
       "         [ 55,  56,  57,  58,  59,  60]],\n",
       "\n",
       "        [[ 85,  86,  87,  88,  89,  90],\n",
       "         [115, 116, 117, 118, 119, 120]],\n",
       "\n",
       "        [[145, 146, 147, 148, 149, 150],\n",
       "         [175, 176, 177, 178, 179, 180]]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens[:,:,4,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3417cd-a017-41cb-b7c3-aa7b85cace62",
   "metadata": {},
   "source": [
    "Here, the the 5th (index=4) row of each sub tensor with dim $5$X$6$ is selected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d4b141-08d8-465f-b5a3-d40134b940a1",
   "metadata": {},
   "source": [
    "## The data explorer's motto : **VISUALIZE, VISUALIZE, VISUALIZE**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1473a517-ad1e-4ee2-bf1a-2315ad44cb44",
   "metadata": {},
   "source": [
    "### PyTorch and NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8a8aba-dbf3-4c5b-b3a7-c8a467c59e3d",
   "metadata": {},
   "source": [
    "PyTorch and NumPy have fucntionality to interact pretty nicely."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebdeade-f315-4388-a6fa-c1a212224bf9",
   "metadata": {},
   "source": [
    "To convert NumPy arrays to Pytorch tensors and vice-versa:\n",
    " * `torch.from_numpy(ndarray)` - NumPy array -> PyTorch tensor. \n",
    " * `torch.Tensor.numpy()` - PyTorch tensor -> NumPy array."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c7853a-2afe-47c4-a539-79819956a864",
   "metadata": {},
   "source": [
    "From an array to a tensor :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "396e92ee-e7ed-4562-bb5a-fac80b0d452f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([1, 2, 3, 4, 5, 6, 7, 8, 9]))"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "arr=np.arange(1,10)\n",
    "tens=torch.from_numpy(arr)\n",
    "arr, tens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5135fb19-2bb6-4891-a00e-77a7953887a9",
   "metadata": {},
   "source": [
    "The default datatype for NumPy is `float64` so when we convert a NumPy array to a PyTorch tensor it retains the `float64` datatype. But many PyTorch calculations default to `float32`.      \n",
    "So to convert a NumPy array(`float64`) to a PyTorch tensor(`float64`) to a Pytorch tensor(`float32`) we do `tensor = torch.from_numpy(array).type(torch.float32)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "aac2aa79-0fdb-4ad1-955a-d01d8e329f18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('int64'), torch.int64)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.dtype, tens.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "108f38eb-024e-44b4-b0ca-62a35a035b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens=torch.from_numpy(arr).type(torch.float32)\n",
    "tens.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643a0924-a9ac-4aed-9e99-43f818e91099",
   "metadata": {},
   "source": [
    "From a tensor to an array :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "d4c56e9c-2868-4515-b1a6-d27698a4065a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]),\n",
       " array([1., 2., 3., 4., 5., 6., 7., 8., 9.], dtype=float32))"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_tens=tens.numpy()\n",
    "tens,numpy_tens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "b22b41c9-397c-4134-9c2b-fc107a13fb21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32, dtype('float32'))"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens.dtype, numpy_tens.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4186ada1-424d-4ef0-976f-9380aca44663",
   "metadata": {},
   "source": [
    "**For both tensors and arrays converted from each other when we change any one theres no change in the other**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "1d83a8d7-370e-43e6-8209-4ad82bab98e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.], dtype=float32),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]))"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_tens+1,tens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "70951d49-8e2a-495f-9a0e-b8c324862fff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_tens+1==tens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "31849f56-13d0-4b98-aa97-98e8a351bdcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2,  3,  4,  5,  6,  7,  8,  9, 10]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]))"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr+1,tens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "8ad47cea-e2f9-4170-83eb-fccd3da04961",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr+1==tens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bc69e2-4cc6-41a3-abf1-8a9af0317850",
   "metadata": {},
   "source": [
    "### Reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf9b544-3aab-4308-845c-2c5328bb85da",
   "metadata": {},
   "source": [
    "To get the same random tensors to make the code reproducable, we use seeds and `torch.manual_seed(seed)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "e47b7b50-4dce-4c87-86ca-7cb377097351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.8823, 0.9150, 0.3829, 0.9593],\n",
       "          [0.3904, 0.6009, 0.2566, 0.7936],\n",
       "          [0.9408, 0.1332, 0.9346, 0.5936]],\n",
       " \n",
       "         [[0.8694, 0.5677, 0.7411, 0.4294],\n",
       "          [0.8854, 0.5739, 0.2666, 0.6274],\n",
       "          [0.2696, 0.4414, 0.2969, 0.8317]]]),\n",
       " tensor([[[0.1053, 0.2695, 0.3588, 0.1994, 0.5472],\n",
       "          [0.0062, 0.9516, 0.0753, 0.8860, 0.5832],\n",
       "          [0.3376, 0.8090, 0.5779, 0.9040, 0.5547],\n",
       "          [0.3423, 0.6343, 0.3644, 0.7104, 0.9464]],\n",
       " \n",
       "         [[0.7890, 0.2814, 0.7886, 0.5895, 0.7539],\n",
       "          [0.1952, 0.0050, 0.3068, 0.1165, 0.9103],\n",
       "          [0.6440, 0.7071, 0.6581, 0.4913, 0.8913],\n",
       "          [0.1447, 0.5315, 0.1587, 0.6542, 0.3278]],\n",
       " \n",
       "         [[0.6532, 0.3958, 0.9147, 0.2036, 0.2018],\n",
       "          [0.2018, 0.9497, 0.6666, 0.9811, 0.0874],\n",
       "          [0.0041, 0.1088, 0.1637, 0.7025, 0.6790],\n",
       "          [0.9155, 0.2418, 0.1591, 0.7653, 0.2979]]]))"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(seed=42)\n",
    "rand1=torch.rand(2,3,4)\n",
    "rand3=torch.rand(3,4,5)\n",
    "rand1,rand3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "d6a8f5a6-50ff-4644-8fd4-2aea6d932bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.8823, 0.9150, 0.3829, 0.9593],\n",
       "          [0.3904, 0.6009, 0.2566, 0.7936],\n",
       "          [0.9408, 0.1332, 0.9346, 0.5936]],\n",
       " \n",
       "         [[0.8694, 0.5677, 0.7411, 0.4294],\n",
       "          [0.8854, 0.5739, 0.2666, 0.6274],\n",
       "          [0.2696, 0.4414, 0.2969, 0.8317]]]),\n",
       " tensor([[[0.1053, 0.2695, 0.3588, 0.1994, 0.5472],\n",
       "          [0.0062, 0.9516, 0.0753, 0.8860, 0.5832],\n",
       "          [0.3376, 0.8090, 0.5779, 0.9040, 0.5547],\n",
       "          [0.3423, 0.6343, 0.3644, 0.7104, 0.9464]],\n",
       " \n",
       "         [[0.7890, 0.2814, 0.7886, 0.5895, 0.7539],\n",
       "          [0.1952, 0.0050, 0.3068, 0.1165, 0.9103],\n",
       "          [0.6440, 0.7071, 0.6581, 0.4913, 0.8913],\n",
       "          [0.1447, 0.5315, 0.1587, 0.6542, 0.3278]],\n",
       " \n",
       "         [[0.6532, 0.3958, 0.9147, 0.2036, 0.2018],\n",
       "          [0.2018, 0.9497, 0.6666, 0.9811, 0.0874],\n",
       "          [0.0041, 0.1088, 0.1637, 0.7025, 0.6790],\n",
       "          [0.9155, 0.2418, 0.1591, 0.7653, 0.2979]]]))"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(seed=42)\n",
    "rand2=torch.rand(2,3,4)\n",
    "rand4=torch.rand(3,4,5)\n",
    "rand2,rand4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a122c275-8b10-43ff-9512-3271ecea8cf2",
   "metadata": {},
   "source": [
    "We need to reset the seed every time to get the same random tensors each time.\n",
    "Each seed gives the same rand tensors on same number of calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "92800f7a-7790-4ca9-b83b-3655b815fea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7576, 0.2793, 0.4031, 0.7347],\n",
       "         [0.0293, 0.7999, 0.3971, 0.7544],\n",
       "         [0.5695, 0.4388, 0.6387, 0.5247]],\n",
       "\n",
       "        [[0.6826, 0.3051, 0.4635, 0.4550],\n",
       "         [0.5725, 0.4980, 0.9371, 0.6556],\n",
       "         [0.3138, 0.1980, 0.4162, 0.2843]]])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(seed=1)\n",
    "rando=torch.rand(2,3,4)\n",
    "rando"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2b0f9b-6547-49ec-8d81-bc3037749e04",
   "metadata": {},
   "source": [
    "Changing the seed changes the random tensors or the flavour of the randomness.\n",
    "All randomness in a computer is pseudo-randomness since a computer itself is a deterministic machine but some theories disagree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f25b800-8599-4383-a578-05d4e71e4925",
   "metadata": {},
   "source": [
    "## GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "37fa5cfb-003a-42d7-9b8b-3300d82ff326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: nvidia-smi: command not found\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "18595318-07c9-4d38-8d63-f2b8881f17c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "28c0a6bd-a9e3-4a8f-a6c7-e01b422d8d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device=\"cuda\" if torch.cuda.is_available else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf1fe45-fe59-4a3c-a36f-c5499c0c247a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tens=torch.rand(2,3)\n",
    "tens_gpu=tens.to(device)\n",
    "tens_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49377c6b-fc54-4f19-a1b7-0f7999df797f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
